#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI æ™ºæ…§èª²ç¨‹å½±ç‰‡ç”Ÿæˆç³»çµ±
ä½¿ç”¨èªéŸ³è­˜åˆ¥ + PDFæ–‡å­—åˆ†æ + AI åˆ†æé€²è¡Œå…§å®¹åŒ¹é…
å®Œå…¨åŸºæ–¼PDFï¼Œè‡ªå‹•æå–é é¢åœ–ç‰‡
"""

import librosa
import whisper
import pdfplumber
import anthropic
import json
import os
import gc
import time
import psutil
from pathlib import Path
from moviepy import (
    ImageClip, AudioFileClip, CompositeVideoClip
)
from datetime import datetime
import fitz  # PyMuPDF for PDF to image conversion
from PIL import Image
# from dotenv import load_dotenv  # å·²ç§»é™¤ dotenvï¼Œæ”¹ç”¨ streamlit.secrets

# è¼‰å…¥ .env æª”æ¡ˆ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

class AILectureCreator:
    def __init__(self, audio_path, pdf_path, output_path="ai_lecture_video.mp4"):
        self.audio_path = audio_path
        self.pdf_path = Path(pdf_path)
        self.output_path = output_path
        # å¾ç’°å¢ƒè®Šé‡è®€å–è¨­å®š
        self.fps = int(os.getenv('VIDEO_FPS', '25'))
        
        # è¨˜æ†¶é«”ç›£æ§
        self.memory_limit_gb = float(os.getenv('MEMORY_LIMIT_GB', '2.0'))  # é è¨­ 2GB è¨˜æ†¶é«”é™åˆ¶
        
        # é€²åº¦ä¿å­˜è·¯å¾‘
        self.progress_file = Path("pdf_progress.json")
        
        # å‰µå»ºè‡¨æ™‚åœ–ç‰‡ç›®éŒ„
        self.temp_images_dir = Path("temp_pdf_images")
        self.temp_images_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ– AI æ¨¡çµ„
        print("ğŸ”§ åˆå§‹åŒ– AI æ¨¡çµ„...")
        
        # å¾ç’°å¢ƒè®Šé‡è®€å–è¨­å®š
        whisper_model_name = os.getenv('WHISPER_MODEL', 'base')
        
        # åˆå§‹åŒ– Whisper
        self.whisper_model = whisper.load_model(whisper_model_name)
        
        # Claude (Anthropic) API è¨­å®š
        self.claude_client = None
        api_key = os.getenv('ANTHROPIC_API_KEY')
        if api_key and api_key != 'your-api-key-here':
            self.claude_client = anthropic.Anthropic(api_key=api_key)
            print("   âœ… Claude API å·²å¾ .env è¼‰å…¥")
        else:
            print("   âš ï¸ æœªè¨­å®šæœ‰æ•ˆçš„ ANTHROPIC_API_KEYï¼Œå°‡ä½¿ç”¨æœ¬åœ°åŒ¹é…ç®—æ³•")
            print("   ğŸ’¡ è«‹åœ¨ .env æª”æ¡ˆè¨­å®šä½ çš„ Anthropic API Key")
    
    def check_memory_usage(self):
        """æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
        memory_info = psutil.virtual_memory()
        used_gb = memory_info.used / (1024**3)
        available_gb = memory_info.available / (1024**3)
        
        print(f"   ğŸ“Š è¨˜æ†¶é«”ä½¿ç”¨: {used_gb:.1f}GB / {memory_info.total/(1024**3):.1f}GB (å¯ç”¨: {available_gb:.1f}GB)")
        
        if available_gb < 0.5:  # å°‘æ–¼ 0.5GB å¯ç”¨è¨˜æ†¶é«”
            print("   âš ï¸ è¨˜æ†¶é«”ä¸è¶³ï¼ŒåŸ·è¡Œåƒåœ¾å›æ”¶...")
            gc.collect()
            time.sleep(1)
            
            # å†æ¬¡æª¢æŸ¥
            memory_info = psutil.virtual_memory()
            available_gb = memory_info.available / (1024**3)
            if available_gb < 0.3:  # é‚„æ˜¯ä¸å¤ 
                raise MemoryError(f"è¨˜æ†¶é«”ä¸è¶³ï¼å¯ç”¨è¨˜æ†¶é«”: {available_gb:.1f}GB")
    
    def save_pdf_progress(self, processed_pages):
        """ä¿å­˜ PDF è™•ç†é€²åº¦"""
        progress_data = {
            'timestamp': datetime.now().isoformat(),
            'processed_count': len(processed_pages),
            'pages': processed_pages
        }
        
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
    
    def load_pdf_progress(self):
        """è¼‰å…¥å·²ä¿å­˜çš„ PDF è™•ç†é€²åº¦"""
        if not self.progress_file.exists():
            return []
        
        try:
            with open(self.progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            
            pages = progress_data.get('pages', [])
            print(f"   ğŸ“‚ è¼‰å…¥å·²ä¿å­˜çš„é€²åº¦: {len(pages)} é ")
            return pages
        except Exception as e:
            print(f"   âš ï¸ è¼‰å…¥é€²åº¦å¤±æ•—: {e}")
            return []

    def transcribe_audio_with_timestamps(self):
        """ä½¿ç”¨ Whisper è½‰æ›èªéŸ³ç‚ºæ–‡å­—ï¼ŒåŒ…å«æ™‚é–“æˆ³"""
        print("ğŸ¤ åˆ†æèªéŸ³å…§å®¹...")
        
        # æª¢æŸ¥è¨˜æ†¶é«”
        self.check_memory_usage()
        
        # ä½¿ç”¨ Whisper è½‰éŒ„éŸ³é »
        result = self.whisper_model.transcribe(
            self.audio_path,
            language='zh',  # å¯ä»¥æ”¹ç‚º 'en' æˆ– None (è‡ªå‹•æª¢æ¸¬)
            word_timestamps=True
        )
        
        # æ•´ç†è½‰éŒ„çµæœ
        segments = []
        for segment in result['segments']:
            segments.append({
                'start': segment['start'],
                'end': segment['end'],
                'text': segment['text'].strip(),
                'words': segment.get('words', [])
            })
        
        total_duration = result.get('duration', librosa.get_duration(path=self.audio_path))
        
        print(f"   âœ… èªéŸ³è½‰éŒ„å®Œæˆï¼Œå…± {len(segments)} å€‹ç‰‡æ®µ")
        print(f"   ğŸ“ è½‰éŒ„å…§å®¹é è¦½: {result['text'][:100]}...")
        
        # æ¸…ç† Whisper æ¨¡å‹è¨˜æ†¶é«”
        del result
        gc.collect()
        
        return {
            'segments': segments,
            'full_text': ' '.join([seg['text'] for seg in segments]),
            'duration': total_duration
        }
    
    def extract_text_from_pdf(self):
        """å¾PDFä¸­æå–æ¯é çš„æ–‡å­—å…§å®¹"""
        print("ğŸ“„ åˆ†æPDFå…§å®¹...")
        
        # è¼‰å…¥å·²ä¿å­˜çš„é€²åº¦
        pdf_pages = self.load_pdf_progress()
        
        if pdf_pages:
            print(f"   ğŸ“‚ ä½¿ç”¨å·²ä¿å­˜çš„é€²åº¦è³‡æ–™: {len(pdf_pages)} é ")
            return pdf_pages
        
        # æª¢æŸ¥PDFæª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not self.pdf_path.exists():
            raise FileNotFoundError(f"PDFæª”æ¡ˆä¸å­˜åœ¨: {self.pdf_path}")
        
        print(f"   ğŸ“– è®€å–PDFæª”æ¡ˆ: {self.pdf_path.name}")
        
        try:
            with pdfplumber.open(self.pdf_path) as pdf:
                total_pages = len(pdf.pages)
                print(f"   ğŸ“„ PDFç¸½é æ•¸: {total_pages}")
                
                pdf_pages = []
                
                for page_index, page in enumerate(pdf.pages):
                    print(f"   ğŸ“„ è™•ç†ç¬¬ {page_index + 1}/{total_pages} é ")
                    
                    try:
                        # æå–æ–‡å­—
                        extracted_text = page.extract_text() or ""
                        
                        # æ¸…ç†æ–‡å­—
                        cleaned_text = ' '.join(extracted_text.split())
                        
                        page_data = {
                            'page_index': page_index,
                            'page_number': page_index + 1,
                            'extracted_text': cleaned_text,
                            'word_count': len(cleaned_text.split()) if cleaned_text else 0
                        }
                        
                        pdf_pages.append(page_data)
                        
                        if cleaned_text:
                            print(f"      âœ… æå–æ–‡å­—: {cleaned_text[:80]}...")
                        else:
                            print(f"      âš ï¸ è©²é æœªæª¢æ¸¬åˆ°æ–‡å­—")
                        
                        # æ¯è™•ç†5é ä¿å­˜ä¸€æ¬¡é€²åº¦
                        if (page_index + 1) % 5 == 0:
                            self.save_pdf_progress(pdf_pages)
                            self.check_memory_usage()
                        
                    except Exception as e:
                        print(f"      âŒ è™•ç†ç¬¬ {page_index + 1} é å¤±æ•—: {e}")
                        # æ·»åŠ ç©ºçµæœä»¥ç¶­æŒç´¢å¼•ä¸€è‡´æ€§
                        pdf_pages.append({
                            'page_index': page_index,
                            'page_number': page_index + 1,
                            'extracted_text': '',
                            'word_count': 0
                        })
                        continue
                
                print(f"   âœ… PDFæ–‡å­—æå–å®Œæˆï¼Œå…± {len(pdf_pages)} é ")
                
                # ä¿å­˜æœ€çµ‚é€²åº¦
                self.save_pdf_progress(pdf_pages)
                
                return pdf_pages
                
        except Exception as e:
            print(f"   âŒ PDFè™•ç†å¤±æ•—: {e}")
            raise e
    
    def convert_pdf_to_images(self, pdf_pages_data):
        """å°‡PDFæ¯é è½‰æ›ç‚ºåœ–ç‰‡"""
        print("ğŸ–¼ï¸ è½‰æ›PDFé é¢ç‚ºåœ–ç‰‡...")
        
        # æ¸…ç†èˆŠçš„è‡¨æ™‚åœ–ç‰‡
        for old_img in self.temp_images_dir.glob("*.png"):
            old_img.unlink()
        
        slides_data = []
        
        try:
            # ä½¿ç”¨ PyMuPDF æ‰“é–‹PDF
            pdf_document = fitz.open(self.pdf_path)
            total_pages = len(pdf_document)
            
            print(f"   ğŸ”„ è½‰æ› {total_pages} é PDFç‚ºåœ–ç‰‡...")
            
            for page_index in range(total_pages):
                try:
                    print(f"   ğŸ“„ è½‰æ›ç¬¬ {page_index + 1}/{total_pages} é ")
                    
                    # ç²å–é é¢
                    page = pdf_document[page_index]
                    
                    # è¨­å®šè¼ƒé«˜çš„è§£æåº¦ä»¥ç²å¾—æ›´å¥½çš„åœ–ç‰‡å“è³ª
                    mat = fitz.Matrix(2.0, 2.0)  # 2å€æ”¾å¤§
                    pix = page.get_pixmap(matrix=mat)
                    
                    # ä¿å­˜ç‚ºåœ–ç‰‡
                    image_path = self.temp_images_dir / f"slide_{page_index+1:03d}.png"
                    pix.save(str(image_path))
                    
                    # ç²å–å°æ‡‰çš„æ–‡å­—å…§å®¹
                    page_text = ""
                    if page_index < len(pdf_pages_data):
                        page_text = pdf_pages_data[page_index]['extracted_text']
                    
                    slide_data = {
                        'slide_index': page_index,
                        'slide_path': image_path,
                        'slide_name': image_path.name,
                        'pdf_page_index': page_index,
                        'pdf_page_number': page_index + 1,
                        'extracted_text': page_text,
                        'word_count': len(page_text.split()) if page_text else 0
                    }
                    
                    slides_data.append(slide_data)
                    
                    print(f"      âœ… å·²è½‰æ›: {image_path.name}")
                    
                    # è¨˜æ†¶é«”ç®¡ç†
                    pix = None
                    if (page_index + 1) % 5 == 0:
                        self.check_memory_usage()
                        gc.collect()
                    
                except Exception as e:
                    print(f"      âŒ è½‰æ›ç¬¬ {page_index + 1} é å¤±æ•—: {e}")
                    continue
            
            pdf_document.close()
            print(f"   âœ… PDFè½‰åœ–ç‰‡å®Œæˆï¼Œå…± {len(slides_data)} å¼µåœ–ç‰‡")
            
            return slides_data
            
        except Exception as e:
            print(f"   âŒ PDFè½‰åœ–ç‰‡å¤±æ•—: {e}")
            raise e
    
    def ai_content_matching(self, speech_data, slides_data):
        """ä½¿ç”¨ AI åˆ†æèªéŸ³å’Œç°¡å ±å…§å®¹çš„åŒ¹é…é—œä¿‚"""
        print("ğŸ¤– AI å…§å®¹åŒ¹é…åˆ†æ...")
        
        if not self.claude_client:
            return self.fallback_content_matching(speech_data, slides_data)
        
        try:
            # æº–å‚™æç¤ºè©
            slides_info = []
            for slide in slides_data:
                slides_info.append({
                    'index': slide['slide_index'],
                    'name': slide['slide_name'],
                    'content': slide['extracted_text'][:200]  # é™åˆ¶é•·åº¦
                })
            
            speech_segments = []
            for segment in speech_data['segments']:
                speech_segments.append({
                    'start': segment['start'],
                    'end': segment['end'],
                    'text': segment['text']
                })
            
            user_prompt = f"""
                ç°¡å ±å…§å®¹:
                {json.dumps(slides_info, ensure_ascii=False, indent=2)}

                èªéŸ³å…§å®¹:
                {json.dumps(speech_segments, ensure_ascii=False, indent=2)}
                """
            system_prompt = """
                ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„èª²ç¨‹å½±ç‰‡è£½ä½œå°å¹«æ‰‹ã€‚
                é€™å€‹ç°¡å ±æ˜¯æŒ‰é †åºè¨­è¨ˆçš„ï¼Œæ¯å¼µç°¡å ±å°æ‡‰ä¸€å€‹æ®µè½çš„èªéŸ³å…§å®¹ï¼Œè«‹è©³ç´°åœ°åˆ†æèªéŸ³å’Œç°¡å ±çš„å…§å®¹ï¼Œåˆ¤æ–·ä»€éº¼æ™‚å€™æ‡‰è©²ä½¿ç”¨å“ªå¼µç°¡å ±ã€‚

                ## åˆ‡æ›åŸå‰‡:
                - ç°¡å ±å¿…é ˆæŒ‰é †åºæ’­æ”¾ (0â†’1â†’2â†’3...)ï¼Œä¸å¯ä»¥è·³éæˆ–é‡è¤‡ã€‚
                - åªæœ‰ç•¶èªéŸ³å…§å®¹æ˜ç¢ºé–‹å§‹è¨è«–ä¸‹ä¸€å¼µç°¡å ±çš„ä¸»é¡Œæ™‚ï¼Œæ‰åˆ‡æ›
                - å¦‚æœèªéŸ³é‚„åœ¨å»¶çºŒç•¶å‰ç°¡å ±çš„ä¸»é¡Œï¼Œå°±ä¸è¦åˆ‡æ›
                - å°‹æ‰¾æ˜ç¢ºçš„ç« ç¯€æ¨™é¡Œã€ç·¨è™Ÿæˆ–ä¸»é¡Œè½‰æ›æ™‚æ©Ÿ
                - æœ€å¾Œä¸€å¼µç°¡å ±æŒçºŒåˆ°éŸ³é »çµæŸ
                - æ¯å¼µç°¡å ±æ‡‰è©²æœ‰è¶³å¤ çš„æ™‚é–“é¡¯ç¤ºï¼Œä¸è¦éçŸ­

                ## åˆ‡æ›æ™‚æ©ŸæŒ‡æ¨™:
                - è½åˆ°æ–°çš„ä¸»é¡Œæ¨™é¡Œ
                - èªéŸ³å…§å®¹èˆ‡ä¸‹ä¸€å¼µç°¡å ±çš„æ¨™é¡Œç¬¦åˆ
                - ç•¶å‰ä¸»é¡Œæ˜é¡¯çµæŸï¼Œé–‹å§‹è¨è«–å…¨æ–°çš„æ¦‚å¿µ

                ## è¼¸å‡ºæ ¼å¼:
                è¼¸å‡ºæ ¼å¼ç‚º JSONï¼ŒåŒ…å«æ¯å¼µç°¡å ±çš„æ™‚é–“ç¯„åœ:
                {{
                "slide_timings": [
                    {{
                        "slide_index": 1,
                        "start_time": 60.0,
                        "end_time": 120.0,
                        "reason": "æ˜ç¢ºè½åˆ°ç›¸ä¼¼çš„è§€å¿µï¼Œä¸”å…§å®¹å®Œå…¨åŒ¹é…ç°¡å ±1"
                    }}
                ]
                }}
                """

            response = self.claude_client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=10000,
                temperature=0.3,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": user_prompt}
                ]
            )
            
            # è§£æ AI å›æ‡‰
            ai_response = response.content[0].text
            print(f"   ğŸ” Claude å®Œæ•´å›æ‡‰:")
            print("=" * 80)
            print(ai_response)
            print("=" * 80)
            
            # æå– JSON å…§å®¹ï¼ˆè™•ç† markdown ä»£ç¢¼å¡Šæ ¼å¼ï¼‰
            import re
            
            # å˜—è©¦å¾ markdown ä»£ç¢¼å¡Šä¸­æå– JSON
            json_match = re.search(r'```json\s*(.*?)\s*```', ai_response, re.DOTALL)
            if json_match:
                json_content = json_match.group(1)
            else:
                # å¦‚æœæ²’æœ‰ markdown æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å›æ‡‰
                json_content = ai_response
            
            print(f"   ğŸ“„ æå–çš„ JSON å…§å®¹:")
            print("-" * 60)
            print(json_content)
            print("-" * 60)
            
            # å˜—è©¦è§£æ JSON
            try:
                timing_data = json.loads(json_content)
                slide_timings = timing_data.get('slide_timings', [])
                
                if not slide_timings:
                    raise ValueError("JSONä¸­æœªæ‰¾åˆ° 'slide_timings' è³‡æ–™")
                
                print(f"   ğŸ“Š æˆåŠŸè§£æ {len(slide_timings)} å€‹ç°¡å ±æ™‚é–“å®‰æ’")
                
                # è½‰æ›ç‚ºåŸä¾†çš„ matches æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
                matches = []
                total_duration = speech_data['duration']
                
                for timing in slide_timings:
                    slide_index = timing['slide_index']
                    start_time = timing['start_time']
                    
                    # è™•ç†Claudeå›æ‡‰ä¸­å¯èƒ½çš„æ¬„ä½åç¨±éŒ¯èª¤
                    if 'end_time' in timing:
                        end_time = timing['end_time']
                    elif 'end' in timing:
                        end_time = timing['end']
                        print(f"   âš ï¸ ä¿®æ­£ç°¡å ± {slide_index} çš„æ¬„ä½åç¨±: 'end' â†’ 'end_time'")
                    else:
                        print(f"   âŒ ç°¡å ± {slide_index} ç¼ºå°‘çµæŸæ™‚é–“æ¬„ä½")
                        continue
                    
                    end_time = min(end_time, total_duration)  # ç¢ºä¿ä¸è¶…ééŸ³é »é•·åº¦
                    
                    # æ‰¾åˆ°é€™å€‹æ™‚é–“ç¯„åœå…§çš„èªéŸ³ç‰‡æ®µ
                    segments_in_range = [
                        seg for seg in speech_data['segments']
                        if seg['start'] >= start_time and seg['end'] <= end_time
                    ]
                    
                    if segments_in_range:
                        # åˆä½µé€™å€‹æ™‚é–“ç¯„åœå…§çš„æ‰€æœ‰èªéŸ³æ–‡æœ¬
                        combined_text = ' '.join([seg['text'] for seg in segments_in_range])
                    else:
                        combined_text = f"æ™‚é–“ç¯„åœ {start_time:.1f}s - {end_time:.1f}s"
                    
                    matches.append({
                        'segment_start': start_time,
                        'segment_end': end_time,
                        'segment_text': combined_text,
                        'recommended_slide': slide_index,
                        'confidence': 0.9,
                        'reason': timing.get('reason', 'æŒ‰é †åºæ’­æ”¾ç°¡å ±')
                    })
                
                print(f"   âœ… AI æ™‚é–“è»¸åˆ†æå®Œæˆï¼Œç”Ÿæˆ {len(matches)} å€‹ç°¡å ±æ®µ")
                return matches
                
            except json.JSONDecodeError as e:
                print(f"   âŒ JSON è§£æéŒ¯èª¤: {e}")
                print(f"   ğŸ“„ æå–çš„ JSON å…§å®¹:\n{json_content[:1000]}...")
                # ä¸ä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆï¼Œè€Œæ˜¯æ‹‹å‡ºéŒ¯èª¤
                raise Exception(f"Claude API å›æ‡‰æ ¼å¼éŒ¯èª¤: {e}")
                
        except Exception as e:
            print(f"   âŒ AI åŒ¹é…å¤±æ•—: {e}")
            # ä¸ä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆï¼Œç›´æ¥æ‹‹å‡ºéŒ¯èª¤
            raise e
    
    def fallback_content_matching(self, speech_data, slides_data):
        """å‚™ç”¨çš„ç°¡å–®åŒ¹é…ç®—æ³•"""
        print("   ğŸ”„ ä½¿ç”¨åŸºæ–¼æ™‚é–“çš„ç°¡å–®åŒ¹é…ç®—æ³•")
        
        segments = speech_data['segments']
        slides = slides_data
        
        matches = []
        total_duration = speech_data['duration']
        
        if not segments or not slides:
            return matches
        
        # ç°¡å–®ç­–ç•¥ï¼šæ ¹æ“šæ™‚é–“å‡å‹»åˆ†é…ç°¡å ±
        for i, segment in enumerate(segments):
            # æ ¹æ“šæ™‚é–“æ¯”ä¾‹é¸æ“‡ç°¡å ±
            progress = segment['start'] / total_duration
            slide_index = min(int(progress * len(slides)), len(slides) - 1)
            
            matches.append({
                'segment_start': segment['start'],
                'segment_end': segment['end'],
                'segment_text': segment['text'],
                'recommended_slide': slide_index,
                'confidence': 0.6,
                'reason': 'åŸºæ–¼æ™‚é–“é †åºçš„è‡ªå‹•åŒ¹é…'
            })
        
        return matches
    
    def create_timeline_from_matches(self, matches, slides_data):
        """æ ¹æ“šåŒ¹é…çµæœå»ºç«‹å½±ç‰‡æ™‚é–“è»¸"""
        print("â° ç”Ÿæˆå½±ç‰‡æ™‚é–“è»¸...")
        
        timeline = []
        
        for match in matches:
            slide_index = match['recommended_slide']
            
            if 0 <= slide_index < len(slides_data):
                slide_info = slides_data[slide_index]
                
                timeline.append({
                    'start_time': match['segment_start'],
                    'end_time': match['segment_end'],
                    'duration': match['segment_end'] - match['segment_start'],
                    'slide_path': slide_info['slide_path'],
                    'slide_name': slide_info['slide_name'],
                    'speech_text': match['segment_text'],
                    'confidence': match['confidence']
                })
        
        # åˆä½µç›¸åŒç°¡å ±çš„é€£çºŒç‰‡æ®µ
        merged_timeline = self.merge_consecutive_slides(timeline)
        
        print(f"   âœ… æ™‚é–“è»¸ç”Ÿæˆå®Œæˆï¼Œå…± {len(merged_timeline)} å€‹ç‰‡æ®µ")
        return merged_timeline
    
    def merge_consecutive_slides(self, timeline):
        """åˆä½µä½¿ç”¨ç›¸åŒç°¡å ±çš„é€£çºŒç‰‡æ®µ"""
        if not timeline:
            return []
        
        merged = []
        current_segment = timeline[0].copy()
        
        for i in range(1, len(timeline)):
            next_segment = timeline[i]
            
            # å¦‚æœæ˜¯ç›¸åŒçš„ç°¡å ±ä¸”æ™‚é–“é€£çºŒï¼Œå°±åˆä½µ
            if (current_segment['slide_path'] == next_segment['slide_path'] and 
                abs(current_segment['end_time'] - next_segment['start_time']) < 1.0):
                
                # åˆä½µç‰‡æ®µ
                current_segment['end_time'] = next_segment['end_time']
                current_segment['duration'] = current_segment['end_time'] - current_segment['start_time']
                current_segment['speech_text'] += ' ' + next_segment['speech_text']
                
            else:
                # ä¸åŒç°¡å ±ï¼ŒåŠ å…¥å‰ä¸€å€‹ç‰‡æ®µä¸¦é–‹å§‹æ–°çš„
                merged.append(current_segment)
                current_segment = next_segment.copy()
        
        # åŠ å…¥æœ€å¾Œä¸€å€‹ç‰‡æ®µ
        merged.append(current_segment)
        
        return merged
    
    def create_video_clips(self, timeline):
        """æ ¹æ“šæ™‚é–“è»¸å»ºç«‹å½±ç‰‡ç‰‡æ®µ"""
        print("ğŸ¥ ç”Ÿæˆå½±ç‰‡ç‰‡æ®µ...")
        
        clips = []
        
        for i, segment in enumerate(timeline):
            try:
                slide_path = segment['slide_path']
                start_time = segment['start_time']
                duration = segment['duration']
                
                # ç¢ºä¿æœ€çŸ­æŒçºŒæ™‚é–“
                duration = max(duration, 1.0)
                
                # å»ºç«‹åœ–ç‰‡ç‰‡æ®µ
                img_clip = ImageClip(str(slide_path), duration=duration)
                img_clip = img_clip.resized(height=720)
                img_clip = img_clip.with_start(start_time)
                
                clips.append(img_clip)
                
                print(f"   ğŸ“„ ç‰‡æ®µ {i+1}: {slide_path.name} ({duration:.1f}s) - {segment['speech_text'][:50]}...")
                
            except Exception as e:
                print(f"   âš ï¸ è™•ç†ç‰‡æ®µ {i+1} æ™‚å‡ºéŒ¯: {e}")
                continue
        
        print(f"   âœ… æˆåŠŸå»ºç«‹ {len(clips)} å€‹å½±ç‰‡ç‰‡æ®µ")
        return clips
    
    def generate_smart_video(self):
        """ç”Ÿæˆæ™ºæ…§èª²ç¨‹å½±ç‰‡"""
        print("ğŸš€ é–‹å§‹ AI æ™ºæ…§å½±ç‰‡ç”Ÿæˆ...")
        print("=" * 60)
        
        # 1. èªéŸ³è½‰æ–‡å­—
        speech_data = self.transcribe_audio_with_timestamps()
        
        # 2. PDFæ–‡å­—æå–
        pdf_pages = self.extract_text_from_pdf()
        
        # 3. å°‡PDFè½‰æ›ç‚ºåœ–ç‰‡
        slides_data = self.convert_pdf_to_images(pdf_pages)
        
        if not slides_data:
            print("âŒ æ²’æœ‰æ‰¾åˆ°ç°¡å ±ï¼")
            return
        
        # 4. AI å…§å®¹åŒ¹é…
        matches = self.ai_content_matching(speech_data, slides_data)
        
        if not matches:
            print("âŒ ç„¡æ³•ç”Ÿæˆå…§å®¹åŒ¹é…ï¼")
            return
        
        # 5. å»ºç«‹æ™‚é–“è»¸
        timeline = self.create_timeline_from_matches(matches, slides_data)
        
        # 6. ç”Ÿæˆå½±ç‰‡ç‰‡æ®µ
        video_clips = self.create_video_clips(timeline)
        
        if not video_clips:
            print("âŒ ç„¡æ³•å»ºç«‹å½±ç‰‡ç‰‡æ®µï¼")
            return
        
        # 7. åˆæˆæœ€çµ‚å½±ç‰‡
        print("ğŸ¬ åˆä½µå½±ç‰‡...")
        audio_clip = AudioFileClip(self.audio_path)
        
        # ç¢ºä¿å½±ç‰‡æ™‚é•·ä¸è¶…ééŸ³é »æ™‚é•·
        video_duration = min(max([clip.end for clip in video_clips]), audio_clip.duration)
        
        final_video = CompositeVideoClip(video_clips, size=(1280, 720))
        final_video = final_video.with_audio(audio_clip)
        final_video = final_video.with_duration(video_duration)
        
        # 8. è¼¸å‡ºå½±ç‰‡
        print(f"ğŸ’¾ æ­£åœ¨å„²å­˜å½±ç‰‡åˆ° {self.output_path}...")
        final_video.write_videofile(
            self.output_path,
            fps=self.fps,
            codec='libx264',
            audio_codec='aac'
        )
        
        print("âœ… AI æ™ºæ…§å½±ç‰‡ç”Ÿæˆå®Œæˆï¼")
        
        # 9. ç”ŸæˆåŒ¹é…å ±å‘Š
        self.generate_matching_report(matches, timeline)
        
        # æ¸…ç†è¨˜æ†¶é«”
        final_video.close()
        audio_clip.close()
        for clip in video_clips:
            clip.close()
        
        # æ¸…ç†è‡¨æ™‚åœ–ç‰‡æª”æ¡ˆ
        self.cleanup_temp_files()
    
    def cleanup_temp_files(self):
        """æ¸…ç†è‡¨æ™‚åœ–ç‰‡æª”æ¡ˆ"""
        try:
            if self.temp_images_dir.exists():
                for temp_file in self.temp_images_dir.glob("*.png"):
                    temp_file.unlink()
                print(f"   ğŸ—‘ï¸ æ¸…ç†è‡¨æ™‚åœ–ç‰‡æª”æ¡ˆ")
        except Exception as e:
            print(f"   âš ï¸ æ¸…ç†è‡¨æ™‚æª”æ¡ˆå¤±æ•—: {e}")
        
        # æ¸…ç†PDFé€²åº¦æª”æ¡ˆ
        if self.progress_file.exists():
            self.progress_file.unlink()
            print("   ğŸ—‘ï¸ æ¸…ç†PDFé€²åº¦æª”æ¡ˆ")
    
    def generate_matching_report(self, matches, timeline):
        """ç”Ÿæˆå…§å®¹åŒ¹é…å ±å‘Š"""
        # å»ºç«‹ logs è³‡æ–™å¤¾ï¼ˆå¦‚ä¸å­˜åœ¨ï¼‰
        logs_dir = Path("logs")
        logs_dir.mkdir(parents=True, exist_ok=True)
        # ç”¢ç”Ÿæ™‚é–“æˆ³æª”å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = logs_dir / f"matching_report_{timestamp}.json"
        
        report = {
            'generation_time': datetime.now().isoformat(),
            'total_matches': len(matches),
            'total_timeline_segments': len(timeline),
            'matches': matches,
            'timeline': []
        }
        
        # è½‰æ› timeline ç‚ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        for segment in timeline:
            report['timeline'].append({
                'start_time': segment['start_time'],
                'end_time': segment['end_time'],
                'duration': segment['duration'],
                'slide_name': segment['slide_name'],
                'speech_text': segment['speech_text'],
                'confidence': segment['confidence']
            })
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š åŒ¹é…å ±å‘Šå·²å„²å­˜è‡³: {report_path}")

def main():
    """ä¸»å‡½æ•¸ - EC2 æœ€ä½³åŒ–ç‰ˆæœ¬"""
    print("ğŸ§  AI æ™ºæ…§èª²ç¨‹å½±ç‰‡ç”Ÿæˆç³»çµ± (EC2 æœ€ä½³åŒ–ç‰ˆ)")
    print("=" * 60)
    
    # è¨­å®š matplotlib å¾Œç«¯ä»¥é¿å… GUI éŒ¯èª¤
    import matplotlib
    matplotlib.use('Agg')
    
    # æª¢æŸ¥ç³»çµ±è³‡æº
    try:
        import psutil
        memory_info = psutil.virtual_memory()
        print(f"ğŸ’¾ ç³»çµ±è¨˜æ†¶é«”: {memory_info.total/(1024**3):.1f}GB (å¯ç”¨: {memory_info.available/(1024**3):.1f}GB)")
        if memory_info.available < 1024**3:  # å°‘æ–¼ 1GB
            print("âš ï¸  è¨˜æ†¶é«”å¯èƒ½ä¸è¶³ï¼Œå»ºè­°ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³")
    except ImportError:
        print("âš ï¸  æœªå®‰è£ psutilï¼Œç„¡æ³•ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨")
    
    # è¨­å®šæª”æ¡ˆè·¯å¾‘
    audio_path = "audio.mp3"
    pdf_path = "presentation.pdf"
    output_path = "ai_lecture_video.mp4"
    
    # æª¢æŸ¥æª”æ¡ˆ
    if not os.path.exists(audio_path):
        print(f"âŒ æ‰¾ä¸åˆ°éŸ³é »æª”æ¡ˆ: {audio_path}")
        return
    
    if not os.path.exists(pdf_path):
        print(f"âŒ æ‰¾ä¸åˆ°ç°¡å ±æª”æ¡ˆ: {pdf_path}")
        return
    
    # æª¢æŸ¥ .env æª”æ¡ˆå’Œ API Key
    if not os.path.exists('.env'):
        print("âš ï¸  æç¤º: æœªæ‰¾åˆ° .env æª”æ¡ˆï¼Œå°‡å»ºç«‹ç¯„ä¾‹æª”æ¡ˆ")
        with open('.env', 'w', encoding='utf-8') as f:
            f.write("# AI æ™ºæ…§èª²ç¨‹å½±ç‰‡ç”Ÿæˆç³»çµ±è¨­å®šæª” - EC2 æœ€ä½³åŒ–ç‰ˆ\n")
            f.write("# è«‹å°‡ your-api-key-here æ›¿æ›ç‚ºä½ çš„å¯¦éš› Anthropic API Key\n\n")
            f.write("ANTHROPIC_API_KEY=your-api-key-here\n")
            f.write("\n# EC2 æœ€ä½³åŒ–è¨­å®š\n")
            f.write("WHISPER_MODEL=base\n")
            f.write("VIDEO_FPS=25\n")
            f.write("MEMORY_LIMIT_GB=1.5\n")
        print("   âœ… å·²å»ºç«‹ .env æª”æ¡ˆï¼Œè«‹ç·¨è¼¯ä¸¦è¨­å®šä½ çš„ API Key")
        print("   ğŸ’¡ å¯åƒè€ƒ env_example.txt æª”æ¡ˆäº†è§£å®Œæ•´è¨­å®šé¸é …")
    
    api_key = os.getenv('ANTHROPIC_API_KEY')
    if not api_key or api_key == 'your-api-key-here':
        print("âš ï¸  æç¤º: è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®šæœ‰æ•ˆçš„ ANTHROPIC_API_KEY")
        print("   ç·¨è¼¯ .env æª”æ¡ˆä¸¦å°‡ 'your-api-key-here' æ›¿æ›ç‚ºå¯¦éš›çš„ API Key")
    
    # å»ºç«‹ AI å½±ç‰‡ç”Ÿæˆå™¨
    try:
        creator = AILectureCreator(audio_path, pdf_path, output_path)
        print("âœ… AI å½±ç‰‡ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # é¡¯ç¤ºç•¶å‰è¨­å®š
        print(f"ğŸ”§ ç•¶å‰è¨­å®š:")
        print(f"   â€¢ Whisper æ¨¡å‹: {os.getenv('WHISPER_MODEL', 'base')}")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ– AI å½±ç‰‡ç”Ÿæˆå™¨å¤±æ•—: {e}")
        import traceback
        print("è©³ç´°éŒ¯èª¤è³‡è¨Š:")
        traceback.print_exc()
        return
    
    # ç”Ÿæˆå½±ç‰‡
    try:
        print("ğŸš€ é–‹å§‹ç”Ÿæˆå½±ç‰‡...")
        start_time = time.time()
        
        creator.generate_smart_video()
        
        end_time = time.time()
        duration = end_time - start_time
        print(f"\nğŸ‰ æˆåŠŸï¼ä½ çš„ AI æ™ºæ…§å½±ç‰‡å·²å„²å­˜ç‚º: {output_path}")
        print(f"â±ï¸  ç¸½è™•ç†æ™‚é–“: {duration/60:.1f} åˆ†é˜")
        print("\nğŸš€ ç³»çµ±ç‰¹è‰²:")
        print("   â€¢ ä½¿ç”¨ Whisper é€²è¡Œç²¾ç¢ºèªéŸ³è­˜åˆ¥")
        print("   â€¢ ä½¿ç”¨ PDF æ–‡å­—åˆ†ææå–ç°¡å ±æ–‡å­—å…§å®¹")
        print("   â€¢ ä½¿ç”¨ Claude AI åˆ†æèªæ„ç›¸é—œæ€§é€²è¡Œæ™ºæ…§åŒ¹é…")
        print("   â€¢ è‡ªå‹•åˆä½µé€£çºŒç›¸åŒç°¡å ±ç‰‡æ®µ")
        print("   â€¢ ç”Ÿæˆè©³ç´°çš„åŒ¹é…åˆ†æå ±å‘Š")
        print("   â€¢ EC2 è¨˜æ†¶é«”æœ€ä½³åŒ–è™•ç†")
        print("   â€¢ æ”¯æ´ç¨‹å¼ä¸­æ–·å¾Œæ¢å¾©é€²åº¦")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ä½¿ç”¨è€…ä¸­æ–·è™•ç†")
        print("ğŸ’¾ å·²ä¿å­˜çš„é€²åº¦æª”æ¡ˆ: pdf_progress.json")
        print("ğŸ”„ ä¸‹æ¬¡åŸ·è¡Œæ™‚å°‡è‡ªå‹•æ¢å¾©é€²åº¦")
    except MemoryError as e:
        print(f"âŒ è¨˜æ†¶é«”ä¸è¶³: {e}")
        print("ğŸ’¡ å»ºè­°çš„è§£æ±ºæ–¹æ¡ˆ:")
        print("   â€¢ ç¸®å°ç°¡å ±åœ–ç‰‡å°ºå¯¸ (å»ºè­° < 1MB)")
        print("   â€¢ æ¸›å°‘ç°¡å ±æ•¸é‡ (åˆ†æ‰¹è™•ç†)")
        print("   â€¢ å‡ç´šåˆ°æ›´å¤§è¨˜æ†¶é«”çš„ EC2 å¯¦ä¾‹")
        print("   â€¢ èª¿æ•´ .env ä¸­çš„ MEMORY_LIMIT_GB è¨­å®š")
        print("   â€¢ è¨­å®š WHISPER_MODEL=tiny ä½¿ç”¨æ›´å°çš„æ¨¡å‹")
        print("ğŸ’¾ å·²ä¿å­˜çš„é€²åº¦æª”æ¡ˆ: pdf_progress.json")
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        print("è©³ç´°éŒ¯èª¤è³‡è¨Š:")
        traceback.print_exc()
        
        # ä¿å­˜éŒ¯èª¤æ—¥èªŒ
        try:
            from datetime import datetime
            from pathlib import Path
            
            logs_dir = Path("logs")
            logs_dir.mkdir(parents=True, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            error_log_path = logs_dir / f"error_log_{timestamp}.txt"
            
            with open(error_log_path, 'w', encoding='utf-8') as f:
                f.write(f"éŒ¯èª¤æ™‚é–“: {datetime.now().isoformat()}\n")
                f.write(f"ç³»çµ±è³‡è¨Š:\n")
                try:
                    memory_info = psutil.virtual_memory()
                    f.write(f"  ç¸½è¨˜æ†¶é«”: {memory_info.total/(1024**3):.1f}GB\n")
                    f.write(f"  å¯ç”¨è¨˜æ†¶é«”: {memory_info.available/(1024**3):.1f}GB\n")
                    f.write(f"  ä½¿ç”¨ç‡: {memory_info.percent}%\n")
                except:
                    f.write("  ç„¡æ³•ç²å–è¨˜æ†¶é«”è³‡è¨Š\n")
                f.write(f"\néŒ¯èª¤è¨Šæ¯: {e}\n")
                f.write("è©³ç´°éŒ¯èª¤è³‡è¨Š:\n")
                f.write(traceback.format_exc())
            
            print(f"ğŸ“ éŒ¯èª¤æ—¥èªŒå·²å„²å­˜è‡³: {error_log_path}")
            print("ğŸ’¾ å·²ä¿å­˜çš„é€²åº¦æª”æ¡ˆ: pdf_progress.json")
        except:
            pass

if __name__ == "__main__":
    main() 